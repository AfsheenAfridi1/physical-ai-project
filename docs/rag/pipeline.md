# RAG Pipeline

1. User asks question
2. Relevant docs retrieved
3. LLM generates answer from context only
